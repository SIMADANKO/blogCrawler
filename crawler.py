import requests
import time
import json
import logging
from bs4 import BeautifulSoup
import os

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def get_all_note_urls(username):
    """é€šè¿‡ API è·å–æ‰€æœ‰ noteUrl å’Œæ ‡é¢˜"""
    page = 1
    all_articles = {}

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    while True:
        # æ„å»º API è¯·æ±‚çš„ URL
        api_url = f"https://note.com/api/v2/creators/{username}/contents?kind=note&page={page}"

        # å‘èµ· GET è¯·æ±‚
        try:
            response = requests.get(api_url, headers=headers, timeout=10)
            response.raise_for_status()
        except requests.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥ï¼Œé”™è¯¯: {e}")
            break

        # è§£æ JSON æ•°æ®
        json_data = response.json()

        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€åä¸€é¡µ
        is_last_page = json_data.get("data", {}).get("isLastPage", True)
        if is_last_page:
            print("âœ… å·²è·å–å…¨éƒ¨æ–‡ç« ã€‚")
            break

        # è·å–é¡µé¢ä¸­çš„æ‰€æœ‰æ–‡ç« æ•°æ®
        notes = json_data.get("data", {}).get("contents", [])

        # å¦‚æœæ²¡æœ‰æ–‡ç« ï¼Œè·³å‡ºå¾ªç¯
        if not notes:
            print("âœ… æ²¡æœ‰æ›´å¤šæ–‡ç« ï¼Œå·²è·å–å…¨éƒ¨æ•°æ®ã€‚")
            break

        # æå–æ¯ç¯‡æ–‡ç« çš„ noteUrl å’Œæ ‡é¢˜
        for item in notes:
            if isinstance(item, dict):
                note_url = item.get('noteUrl')
                title = item.get('name')
                publish_at = item.get('publishAt')
                if note_url and title:
                    print(f"Note URL: {note_url}, Title: {title}, Time: {publish_at}")
                    all_articles[note_url] = {
                        "title": title,
                        "url": note_url,
                        "timestamp": publish_at  # åŠ å…¥æ—¶é—´æˆ³
                    }
        # ä¸‹ä¸€é¡µ
        page += 1
        time.sleep(1)  # é˜²æ­¢è¯·æ±‚è¿‡å¿«è¢«é™åˆ¶

    # æ‰“å°æ‰€æœ‰è·å–çš„æ–‡ç« é“¾æ¥å’Œæ ‡é¢˜
    print(f"\nâœ… å…±æ‰¾åˆ° {len(all_articles)} ç¯‡æ–‡ç« é“¾æ¥ï¼š\n")
    for i, (url, article) in enumerate(all_articles.items(), 1):
        print(f"{i:02d}: {article['url']} ({article['title']})")

    return all_articles


def get_article_content(url, timestamp):
    """è®¿é—®æ–‡ç«  URLï¼Œæå–æ­£æ–‡å†…å®¹å¹¶è¿”å›ï¼Œä¿ç•™åŸæ–‡æ ¼å¼"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    print(f"\nğŸ“¥ æ­£åœ¨è®¿é—®æ–‡ç« : {url}")
    print(timestamp)

    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
    except requests.RequestException as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥ï¼Œé”™è¯¯: {e}")
        return None

    soup = BeautifulSoup(response.text, 'lxml')

    content_div = soup.find('div', {'data-name': 'body', 'class': 'note-common-styles__textnote-body'}) or \
                  soup.find('div', class_='o-noteContent__body')

    if content_div:
        content = content_div.get_text(separator='\n', strip=True)
        if timestamp:
            content = f"{timestamp}\n\n{content}"  # å°†æ—¶é—´æˆ³æ’å…¥æ­£æ–‡å¼€å¤´
        return content
    else:
        print("âŒ æœªæ‰¾åˆ°æ­£æ–‡å†…å®¹\n")
        return None


def save_to_json(all_articles):
    """å°†æ–‡ç« çš„æ ‡é¢˜ã€æ­£æ–‡å†…å®¹å’Œ URL ä¿å­˜åˆ° JSON æ–‡ä»¶ä¸­"""
    results = {}

    for url, article in all_articles.items():
        title = article["title"]
        timestamp = article["timestamp"]
        content = get_article_content(url, timestamp)

        if content:
            results[f"{timestamp[:10]}-{title}"] = {
                "title": title,
                "text": content,
                "url": url
            }

    try:
        with open('note_articles.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        print("âœ… æ–‡ç« æ•°æ®å·²ä¿å­˜åˆ° note_articles.json")
    except Exception as e:
        print(f"âŒ ä¿å­˜ JSON æ–‡ä»¶å¤±è´¥: {e}")


def main():
    # æŒ‡å®šç”¨æˆ·å
    username = "saratoga623"

    # è·å–æ‰€æœ‰ noteUrl å’Œæ ‡é¢˜
    articles = get_all_note_urls(username)

    # ä¿å­˜åˆ° JSON æ–‡ä»¶
    save_to_json(articles)


if __name__ == "__main__":
    main()
